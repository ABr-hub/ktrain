{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import graph as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Classification in Graphs\n",
    "\n",
    "\n",
    "In this notebook, we will use *ktrain* to perform node classificaiton on the PubMed Diabetes citation graph.  In the PubMed graph, each node represents a paper pertaining to one of three topics:  *Diabetes Mellitus - Experimental*, *Diabetes Mellitus - Type 1*, and *Diabetes Mellitus - Type 2*.  Links represent citations between papers.  The attributes or features assigned to each node is a vector of words in each paper and their corresponding TF-IDF scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest subgraph statistics: 19717 nodes, 44327 edges\n",
      "Size of training graph: 15774 nodes\n",
      "Labeled nodes in training graph: 788 (training)\n",
      "Unlabeled nodes in training graph: 14986 (validation)\n",
      "\n",
      "3943 additional nodes held out for testing\n",
      "Size of graph with added holdout nodes: 19717\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'data/pubmed/Pubmed-Diabetes/data'\n",
    "(train_data, val_data, preproc, \n",
    " df_holdout, G_complete)        = gr.graph_nodes_from_csv(DATADIR+'/pubmed-nodes.tab',\n",
    "                                           DATADIR+'/pubmed-edges.tab',\n",
    "                                           sample_size=10, holdout_pct=0.2,\n",
    "                                           train_pct=0.05, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Build a Model and Wrap in Learner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphsage: GraphSAGE:  http://arxiv.org/pdf/1607.01759.pdf\n"
     ]
    }
   ],
   "source": [
    "gr.print_node_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "learner = ktrain.get_learner(model=gr.graph_node_classifier('graphsage', train_data), \n",
    "                             train_data=train_data, \n",
    "                             val_data=val_data, \n",
    "                             batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3:  Estimate LR \n",
    "Given the small number of batches per epoch, a larger number of epochs is required to estimate the learning rate. We will cap it at 100 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 1.1014 - acc: 0.3757\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1053 - acc: 0.3639\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0938 - acc: 0.4110\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0994 - acc: 0.3953\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.1090 - acc: 0.3744\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.1032 - acc: 0.3782\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.1096 - acc: 0.3756\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0985 - acc: 0.3581\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.1027 - acc: 0.3718\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0964 - acc: 0.3665\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0931 - acc: 0.4253\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0974 - acc: 0.3823\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 1.1020 - acc: 0.3507\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0913 - acc: 0.3783\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0944 - acc: 0.3966\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0984 - acc: 0.3874\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.1050 - acc: 0.3607\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0988 - acc: 0.3875\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.1069 - acc: 0.3539\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0991 - acc: 0.3613\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0989 - acc: 0.3586\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0904 - acc: 0.4023\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0918 - acc: 0.3835\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0941 - acc: 0.3993\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.1023 - acc: 0.3909\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 1.0999 - acc: 0.3997\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0987 - acc: 0.3782\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.0880 - acc: 0.3809\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.1044 - acc: 0.3678\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0879 - acc: 0.4032\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0898 - acc: 0.3901\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0813 - acc: 0.4062\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0876 - acc: 0.3921\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0869 - acc: 0.3782\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0699 - acc: 0.4297\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0599 - acc: 0.4581\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0607 - acc: 0.4464\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0612 - acc: 0.4567\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.0558 - acc: 0.4450\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0432 - acc: 0.4766\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0410 - acc: 0.4790\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0195 - acc: 0.4896\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0169 - acc: 0.5461\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0061 - acc: 0.5366\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9826 - acc: 0.5969\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9579 - acc: 0.6256\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9322 - acc: 0.6224\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9007 - acc: 0.6618\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.8551 - acc: 0.7122\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.7994 - acc: 0.7513\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.7573 - acc: 0.7697\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6886 - acc: 0.7957\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.6427 - acc: 0.7944\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5903 - acc: 0.8102\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5502 - acc: 0.8285\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.4736 - acc: 0.8481\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.4303 - acc: 0.8607\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.4412 - acc: 0.8547\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3940 - acc: 0.8546\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.3540 - acc: 0.8795\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3186 - acc: 0.8848\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3872 - acc: 0.8461\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3060 - acc: 0.8919\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3167 - acc: 0.8886\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3177 - acc: 0.8808\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2686 - acc: 0.9005\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3197 - acc: 0.8821\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2998 - acc: 0.8914\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2963 - acc: 0.8809\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2881 - acc: 0.8997\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2861 - acc: 0.8874\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2857 - acc: 0.8887\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.2420 - acc: 0.8978\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3094 - acc: 0.8895\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2943 - acc: 0.8867\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3187 - acc: 0.8835\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3307 - acc: 0.8757\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2863 - acc: 0.8848\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2014 - acc: 0.9254\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2367 - acc: 0.9071\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2889 - acc: 0.8940\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3195 - acc: 0.8769\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.4249 - acc: 0.8586\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3279 - acc: 0.8743\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3074 - acc: 0.8854\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3210 - acc: 0.8808\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4154 - acc: 0.8612\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.4375 - acc: 0.8429\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4786 - acc: 0.8259\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6838 - acc: 0.8063\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6471 - acc: 0.8141\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.5741 - acc: 0.8411\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.6951 - acc: 0.8092\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9104 - acc: 0.8180\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.0442 - acc: 0.7670\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1549 - acc: 0.7710\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.2433 - acc: 0.7735\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.5234 - acc: 0.8101\n",
      "Epoch 99/100\n",
      " 3/12 [======>.......................] - ETA: 0s - loss: 2.0501 - acc: 0.7760\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Train the Model\n",
    "We will train the model using `autofit`, which uses a triangular learning rate policy.  The training will automatically stop when the validation accuracy no longer improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping automatically enabled at patience=5\n",
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.005...\n",
      "Epoch 1/1024\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 1.0654 - acc: 0.4118 - val_loss: 0.9983 - val_acc: 0.4909\n",
      "Epoch 2/1024\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.9724 - acc: 0.5556 - val_loss: 0.8695 - val_acc: 0.6400\n",
      "Epoch 3/1024\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.8471 - acc: 0.7029 - val_loss: 0.7337 - val_acc: 0.7494\n",
      "Epoch 4/1024\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.7332 - acc: 0.7728 - val_loss: 0.6309 - val_acc: 0.7821\n",
      "Epoch 5/1024\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.6164 - acc: 0.8031 - val_loss: 0.5784 - val_acc: 0.7881\n",
      "Epoch 6/1024\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.5460 - acc: 0.8357 - val_loss: 0.5538 - val_acc: 0.7910\n",
      "Epoch 7/1024\n",
      "13/13 [==============================] - 6s 454ms/step - loss: 0.4918 - acc: 0.8514 - val_loss: 0.5218 - val_acc: 0.8072\n",
      "Epoch 8/1024\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 0.4467 - acc: 0.8611 - val_loss: 0.5137 - val_acc: 0.8104\n",
      "Epoch 9/1024\n",
      "13/13 [==============================] - 6s 495ms/step - loss: 0.4202 - acc: 0.8562 - val_loss: 0.4980 - val_acc: 0.8177\n",
      "Epoch 10/1024\n",
      "13/13 [==============================] - 6s 442ms/step - loss: 0.3760 - acc: 0.8767 - val_loss: 0.4993 - val_acc: 0.8128\n",
      "Epoch 11/1024\n",
      "13/13 [==============================] - 6s 485ms/step - loss: 0.3713 - acc: 0.8719 - val_loss: 0.5051 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00011: Reducing Max LR on Plateau: new max lr will be 0.0025 (if not early_stopping).\n",
      "Epoch 12/1024\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.3358 - acc: 0.8925 - val_loss: 0.4978 - val_acc: 0.8122\n",
      "Epoch 13/1024\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.3188 - acc: 0.9119 - val_loss: 0.5019 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00013: Reducing Max LR on Plateau: new max lr will be 0.00125 (if not early_stopping).\n",
      "Epoch 14/1024\n",
      "13/13 [==============================] - 6s 454ms/step - loss: 0.3038 - acc: 0.9094 - val_loss: 0.4976 - val_acc: 0.8173\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00014: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37e8ab31d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(0.005, monitor='val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "#### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "Diabetes_Mellitus-Experimental       0.77      0.82      0.80      3122\n",
      "      Diabetes_Mellitus_Type_1       0.83      0.79      0.81      5967\n",
      "      Diabetes_Mellitus_Type_2       0.84      0.85      0.84      5897\n",
      "\n",
      "                      accuracy                           0.82     14986\n",
      "                     macro avg       0.81      0.82      0.81     14986\n",
      "                  weighted avg       0.82      0.82      0.82     14986\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2561,  395,  166],\n",
       "       [ 449, 4703,  815],\n",
       "       [ 308,  595, 4994]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Predictor Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transductive Inference:  Making Predictions for Unlabeled Nodes in Original Training Graph\n",
    "In transductive inference, we make predictions for unlabeled nodes whose features are visible during training. Making predictions on validation nodes in the training graph is transductive inference.\n",
    "\n",
    "Let's see how well our prediction is for the first validation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02923679, 0.13542812, 0.8353351 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.predict_transductive(val_data.ids[0:1], return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions for all validation nodes and visually compare some of them with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = p.predict_transductive(val_data.ids, return_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = preproc.df[preproc.df.index.isin(val_data.ids)]['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diabetes_Mellitus_Type_1</td>\n",
       "      <td>Diabetes_Mellitus_Type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "      <td>Diabetes_Mellitus_Type_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes_Mellitus-Experimental</td>\n",
       "      <td>Diabetes_Mellitus-Experimental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ground Truth                       Predicted\n",
       "0        Diabetes_Mellitus_Type_2        Diabetes_Mellitus_Type_2\n",
       "1        Diabetes_Mellitus_Type_1        Diabetes_Mellitus_Type_1\n",
       "2        Diabetes_Mellitus_Type_2        Diabetes_Mellitus_Type_2\n",
       "3        Diabetes_Mellitus_Type_2        Diabetes_Mellitus_Type_2\n",
       "4  Diabetes_Mellitus-Experimental  Diabetes_Mellitus-Experimental"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(zip(y_true, y_pred), columns=['Ground Truth', 'Predicted']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inductive Inference:  Making Predictions for New Nodes Not in the Original Training Graph\n",
    "In inductive inference, we make predictions for entirely new nodes that were not present in the traning graph.  The features or attributes of these nodes were **not** visible during training.  We consider a graph where the heldout nodes are added back into the training graph, which yields the original graph of 19,7171 nodes. This graph, `G_complete` was returned as the last return value of `graph_nodes_from_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = p.predict_inductive(df_holdout, G_complete, return_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_holdout['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260207963479584"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(y_true == np.array(y_pred)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an **82.26%** accuracy, we see that inductive performance is quite good and comparable to transductive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
